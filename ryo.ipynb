{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "from pathlib import Path\n",
    "import create_dataset as cd\n",
    "import feature_engineering as fe\n",
    "import os \n",
    "from prep import * \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tim = pd.read_csv('/Users/ryonamba/Documents/VU/VU-master_year_1/ML_quantified_self/ML4QS/datasets/raw_data_tim_copy.csv')\n",
    "data_sien = pd.read_csv('/Users/ryonamba/Documents/VU/VU-master_year_1/ML_quantified_self/ML4QS/datasets/raw_data_sien_copy.csv')\n",
    "data_tim2 = pd.read_csv('/Users/ryonamba/Documents/VU/VU-master_year_1/ML_quantified_self/ML4QS/datasets/raw_data_tim_2_copy.csv')\n",
    "data_sien2 = pd.read_csv('/Users/ryonamba/Documents/VU/VU-master_year_1/ML_quantified_self/ML4QS/datasets/raw_data_sien_copy.csv')\n",
    "\n",
    "data_tim = data_tim.drop(columns = ['Unnamed: 0'])\n",
    "data_sien = data_sien.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_num</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Time (s)</th>\n",
       "      <th>X (m/s^2)</th>\n",
       "      <th>Y (m/s^2)</th>\n",
       "      <th>Z (m/s^2)</th>\n",
       "      <th>X (rad/s)</th>\n",
       "      <th>Y (rad/s)</th>\n",
       "      <th>Z (rad/s)</th>\n",
       "      <th>name_climber</th>\n",
       "      <th>grading</th>\n",
       "      <th>num_attempt</th>\n",
       "      <th>fall_top</th>\n",
       "      <th>outdoor</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-07 16:36:31.299000000</td>\n",
       "      <td>0.202257</td>\n",
       "      <td>0.616807</td>\n",
       "      <td>0.545096</td>\n",
       "      <td>-0.119170</td>\n",
       "      <td>-0.738735</td>\n",
       "      <td>-0.693665</td>\n",
       "      <td>-0.053444</td>\n",
       "      <td>0</td>\n",
       "      <td>4c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-07 16:36:31.399774729</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.427085</td>\n",
       "      <td>-0.449999</td>\n",
       "      <td>0.075464</td>\n",
       "      <td>-0.314339</td>\n",
       "      <td>-0.378076</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>0</td>\n",
       "      <td>4c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-07 16:36:31.500549459</td>\n",
       "      <td>0.604846</td>\n",
       "      <td>0.570240</td>\n",
       "      <td>0.152899</td>\n",
       "      <td>-0.213106</td>\n",
       "      <td>-0.273812</td>\n",
       "      <td>-0.442562</td>\n",
       "      <td>-0.130227</td>\n",
       "      <td>0</td>\n",
       "      <td>4c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-07 16:36:31.601324189</td>\n",
       "      <td>0.806141</td>\n",
       "      <td>0.295633</td>\n",
       "      <td>-0.453686</td>\n",
       "      <td>0.244799</td>\n",
       "      <td>-0.260747</td>\n",
       "      <td>-0.114135</td>\n",
       "      <td>-0.019194</td>\n",
       "      <td>0</td>\n",
       "      <td>4c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-07 16:36:31.702098919</td>\n",
       "      <td>1.007435</td>\n",
       "      <td>0.206272</td>\n",
       "      <td>-0.927811</td>\n",
       "      <td>-0.512616</td>\n",
       "      <td>-0.160211</td>\n",
       "      <td>-0.226173</td>\n",
       "      <td>-0.211577</td>\n",
       "      <td>0</td>\n",
       "      <td>4c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5186</th>\n",
       "      <td>40</td>\n",
       "      <td>2023-06-14 17:02:20.736479365</td>\n",
       "      <td>62.783481</td>\n",
       "      <td>0.138590</td>\n",
       "      <td>-1.738872</td>\n",
       "      <td>-0.396787</td>\n",
       "      <td>-0.371624</td>\n",
       "      <td>-0.194527</td>\n",
       "      <td>-0.130351</td>\n",
       "      <td>1</td>\n",
       "      <td>5b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5187</th>\n",
       "      <td>40</td>\n",
       "      <td>2023-06-14 17:02:20.938609523</td>\n",
       "      <td>62.984758</td>\n",
       "      <td>-0.756452</td>\n",
       "      <td>-0.380505</td>\n",
       "      <td>0.312611</td>\n",
       "      <td>0.064059</td>\n",
       "      <td>0.111573</td>\n",
       "      <td>-0.053014</td>\n",
       "      <td>1</td>\n",
       "      <td>5b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>40</td>\n",
       "      <td>2023-06-14 17:02:21.140739682</td>\n",
       "      <td>63.186036</td>\n",
       "      <td>-0.321295</td>\n",
       "      <td>-0.189666</td>\n",
       "      <td>-0.070279</td>\n",
       "      <td>-0.062600</td>\n",
       "      <td>-0.059749</td>\n",
       "      <td>-0.085358</td>\n",
       "      <td>1</td>\n",
       "      <td>5b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>40</td>\n",
       "      <td>2023-06-14 17:02:21.342869841</td>\n",
       "      <td>63.387314</td>\n",
       "      <td>-0.421361</td>\n",
       "      <td>-0.344314</td>\n",
       "      <td>0.504001</td>\n",
       "      <td>0.049513</td>\n",
       "      <td>-0.251242</td>\n",
       "      <td>0.149490</td>\n",
       "      <td>1</td>\n",
       "      <td>5b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>40</td>\n",
       "      <td>2023-06-14 17:02:21.545000000</td>\n",
       "      <td>63.588592</td>\n",
       "      <td>1.043850</td>\n",
       "      <td>0.042929</td>\n",
       "      <td>-0.344855</td>\n",
       "      <td>0.249277</td>\n",
       "      <td>-1.278707</td>\n",
       "      <td>0.013051</td>\n",
       "      <td>1</td>\n",
       "      <td>5b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33791 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_num                      datetime   Time (s)  X (m/s^2)  \\\n",
       "0            15 2023-06-07 16:36:31.299000000   0.202257   0.616807   \n",
       "1            15 2023-06-07 16:36:31.399774729   0.403552   0.427085   \n",
       "2            15 2023-06-07 16:36:31.500549459   0.604846   0.570240   \n",
       "3            15 2023-06-07 16:36:31.601324189   0.806141   0.295633   \n",
       "4            15 2023-06-07 16:36:31.702098919   1.007435   0.206272   \n",
       "...         ...                           ...        ...        ...   \n",
       "5186         40 2023-06-14 17:02:20.736479365  62.783481   0.138590   \n",
       "5187         40 2023-06-14 17:02:20.938609523  62.984758  -0.756452   \n",
       "5188         40 2023-06-14 17:02:21.140739682  63.186036  -0.321295   \n",
       "5189         40 2023-06-14 17:02:21.342869841  63.387314  -0.421361   \n",
       "5190         40 2023-06-14 17:02:21.545000000  63.588592   1.043850   \n",
       "\n",
       "      Y (m/s^2)  Z (m/s^2)  X (rad/s)  Y (rad/s)  Z (rad/s)  name_climber  \\\n",
       "0      0.545096  -0.119170  -0.738735  -0.693665  -0.053444             0   \n",
       "1     -0.449999   0.075464  -0.314339  -0.378076   0.015612             0   \n",
       "2      0.152899  -0.213106  -0.273812  -0.442562  -0.130227             0   \n",
       "3     -0.453686   0.244799  -0.260747  -0.114135  -0.019194             0   \n",
       "4     -0.927811  -0.512616  -0.160211  -0.226173  -0.211577             0   \n",
       "...         ...        ...        ...        ...        ...           ...   \n",
       "5186  -1.738872  -0.396787  -0.371624  -0.194527  -0.130351             1   \n",
       "5187  -0.380505   0.312611   0.064059   0.111573  -0.053014             1   \n",
       "5188  -0.189666  -0.070279  -0.062600  -0.059749  -0.085358             1   \n",
       "5189  -0.344314   0.504001   0.049513  -0.251242   0.149490             1   \n",
       "5190   0.042929  -0.344855   0.249277  -1.278707   0.013051             1   \n",
       "\n",
       "     grading  num_attempt  fall_top  outdoor  Unnamed: 0  \n",
       "0         4c            1         0      0.0         NaN  \n",
       "1         4c            1         0      0.0         NaN  \n",
       "2         4c            1         0      0.0         NaN  \n",
       "3         4c            1         0      0.0         NaN  \n",
       "4         4c            1         0      0.0         NaN  \n",
       "...      ...          ...       ...      ...         ...  \n",
       "5186      5b            1         0      NaN         NaN  \n",
       "5187      5b            1         0      NaN         NaN  \n",
       "5188      5b            1         0      NaN         NaN  \n",
       "5189      5b            1         0      NaN         NaN  \n",
       "5190      5b            1         0      NaN         NaN  \n",
       "\n",
       "[33791 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cd.combine_start_dfs(data_sien, data_sien2, data_tim, data_tim2)\n",
    "# change name climber to numerical value\n",
    "data['name_climber'] = data['name_climber'].map({'sien':0,'tim':1})\n",
    "# drop weird column (SIEN's FAULT)\n",
    "data = data.drop(columns = ['Time (s).1'])\n",
    "# drop climber rating var \n",
    "data = cd.drop_climber_rating(data)\n",
    "# add datetime var \n",
    "data = cd.add_datetime(data)\n",
    "data\n",
    "# add heart-rate var\n",
    "\n",
    "\n",
    "\n",
    "# cut falls \n",
    "# data = cd.cut_fall(data)\n",
    "\n",
    "# data = fe.features(data)\n",
    "# data.grading = data.grading.apply(fe.french_grade_to_num)\n",
    "\n",
    "# data = create_snippets(data, 20, 5)\n",
    "# data = change_climb_ID(data)\n",
    "\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heart rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- time jumps are inconsistent (sometimes 5, sometimes 10)\n",
    "- extract & map heart rate values within a datetime range to their group -> dict? \n",
    "    - iterate through df groups\n",
    "        - iterate through json file \n",
    "        \n",
    "- fit values to entries in each group (will have some nans)\n",
    "- interpolate missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('heartrate/heart_rate-2023-06-07 copy.json', 'r') as f1: \n",
    "    hr_json1 = json.load(f1)\n",
    "with open('heartrate/heart_rate-2023-06-14 copy.json', 'r') as f2: \n",
    "    hr_json2 = json.load(f2)\n",
    "\n",
    "\n",
    "# convert entries to datetime obj & put values in list \n",
    "hr_data1 = [] \n",
    "for heart_entry in hr_json1:\n",
    "    dt = heart_entry['dateTime']\n",
    "    hr = heart_entry['value']['bpm']\n",
    "    hr_data1.append((dt, hr))\n",
    "\n",
    "hr_data2 = []\n",
    "for heart_entry in hr_json2:\n",
    "    dt = heart_entry['dateTime']\n",
    "    hr = heart_entry['value']['bpm']\n",
    "    hr_data2.append((dt, hr))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "fitbit DatetimeIndex(['2023-06-07 13:12:52', '2023-06-07 13:12:55',\n",
      "               '2023-06-07 13:12:58', '2023-06-07 13:13:01',\n",
      "               '2023-06-07 13:13:04', '2023-06-07 13:13:06',\n",
      "               '2023-06-07 13:13:09', '2023-06-07 13:13:10',\n",
      "               '2023-06-07 13:13:13', '2023-06-07 13:13:16',\n",
      "               '2023-06-07 13:13:18', '2023-06-07 13:13:21',\n",
      "               '2023-06-07 13:13:22', '2023-06-07 13:13:24',\n",
      "               '2023-06-07 13:13:29', '2023-06-07 13:13:39',\n",
      "               '2023-06-07 13:13:44', '2023-06-07 13:13:49',\n",
      "               '2023-06-07 13:13:54', '2023-06-07 13:13:59',\n",
      "               '2023-06-07 13:14:04', '2023-06-07 13:14:09',\n",
      "               '2023-06-07 13:14:14', '2023-06-07 13:14:19',\n",
      "               '2023-06-07 13:14:24', '2023-06-07 13:14:29',\n",
      "               '2023-06-07 13:14:34', '2023-06-07 13:14:39',\n",
      "               '2023-06-07 13:14:44', '2023-06-07 13:14:49',\n",
      "               '2023-06-07 13:14:54', '2023-06-07 13:14:59'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "df DatetimeIndex(['2023-06-07 13:12:51.971851298',\n",
      "               '2023-06-07 13:12:54.997390243',\n",
      "               '2023-06-07 13:12:58.022929189',\n",
      "               '2023-06-07 13:13:01.048468135',\n",
      "               '2023-06-07 13:13:03.973155782',\n",
      "               '2023-06-07 13:13:05.990181746',\n",
      "               '2023-06-07 13:13:09.015720692',\n",
      "               '2023-06-07 13:13:10.024233674',\n",
      "               '2023-06-07 13:13:13.049772619',\n",
      "               '2023-06-07 13:13:15.974460267',\n",
      "               '2023-06-07 13:13:17.991486231',\n",
      "               '2023-06-07 13:13:21.017025177',\n",
      "               '2023-06-07 13:13:22.025538158',\n",
      "               '2023-06-07 13:13:24.042564122',\n",
      "               '2023-06-07 13:13:28.984277734',\n",
      "               '2023-06-07 13:13:38.968556254',\n",
      "               '2023-06-07 13:13:44.011121164',\n",
      "               '2023-06-07 13:13:48.952834775',\n",
      "               '2023-06-07 13:13:53.995399685',\n",
      "               '2023-06-07 13:12:54.896538945',\n",
      "               '2023-06-07 13:12:59.838252557',\n",
      "               '2023-06-07 13:13:04.880817466',\n",
      "               '2023-06-07 13:13:09.822531077',\n",
      "               '2023-06-07 13:13:14.865095987',\n",
      "               '2023-06-07 13:13:19.907660896',\n",
      "               '2023-06-07 13:13:24.849374508',\n",
      "               '2023-06-07 13:13:29.891939417',\n",
      "               '2023-06-07 13:13:34.833653029',\n",
      "               '2023-06-07 13:13:39.876217938',\n",
      "               '2023-06-07 13:13:44.817931549',\n",
      "               '2023-06-07 13:13:49.860496459',\n",
      "               '2023-06-07 13:13:54.903061369'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "fit_datetimes = [x[0] for x in hr_data1]\n",
    "fit_hr = [x[1] for x in hr_data1]\n",
    "\n",
    "# convert fitbit times to datetime obj\n",
    "fit_datetimes = pd.to_datetime(fit_datetimes)\n",
    "\n",
    "# NOTE: OK! but need to do this for only the datetimes within a certain interval, cuz otherwise it's gonna match each row in the df\n",
    "# NOTE: maybe try not to merge dfs, but init a df and then do the masks\n",
    "# NOTE: adapt this to extract heartrate shit then  \n",
    "\n",
    "# TODO: INIT null HR variable here? \n",
    "if not 'heart-rate' in data:\n",
    "    data.insert(2, 'heart-rate', float(\"nan\"))\n",
    "\n",
    "# group by climbID & get datetime intervals \n",
    "for group_name, group_data in data.groupby(\"entry_num\"):\n",
    "\n",
    "    # gets all fitbit datetimes within the given interval \n",
    "    start_time = group_data.iloc[0]['datetime']\n",
    "    end_time = group_data.iloc[-1]['datetime']\n",
    "    filtered = fit_datetimes[(fit_datetimes >= start_time) & (fit_datetimes <= end_time)]\n",
    "\n",
    "    # TODO: get \n",
    "    # map & retrieve closests df datetimes to fitbit datetimes per group \n",
    "    closest_datetimes = filtered.map(lambda x: data['datetime'].iloc[(data['datetime'] - x).abs().idxmin()])    \n",
    "    print(len(filtered))\n",
    "    print(len(closest_datetimes))\n",
    "\n",
    "    print('fitbit', filtered)\n",
    "    print('df', closest_datetimes)\n",
    "\n",
    "    break \n",
    "\n",
    "    # Filter the dataframe based on the datetime interval\n",
    "    # filtered_df = data[(df['timestamp'] >= start_datetime) & (df['timestamp'] <= end_datetime)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find closest respective dates\n",
    "# closest_dates = fit_datetimes.map(lambda x: data['datetime'].iloc[(data['datetime'] - x).abs().idxmin()])\n",
    "# print(closest_dates)\n",
    "\n",
    "\n",
    "# # Create a DataFrame with the closest respective dates\n",
    "# df_new = pd.DataFrame({'closest_datetime': closest_dates, 'new_datetime': fit_datetimes})\n",
    "\n",
    "# # Merge the original DataFrame with the closest respective dates\n",
    "# merged_df = pd.merge(data, df_new, left_on='datetime', right_on='closest_datetime', how='outer')\n",
    "\n",
    "# merged_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2023-06-07 13:12:51.871000-02:00\n",
      "2023-06-07 13:15:00.053000-02:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_datetimes = [x[0] for x in hr_data1]\n",
    "hr = [x[1] for x in hr_data1]\n",
    "\n",
    "# iterate through climb IDs\n",
    "for group_name, group_data in data.groupby(\"entry_num\"):\n",
    "    print(group_name)\n",
    "    print(group_data.iloc[0]['datetime'])\n",
    "    print(group_data.iloc[-1]['datetime'])\n",
    "\n",
    "    new_datetimes = pd.to_datetime(new_datetimes)\n",
    "\n",
    "    # closest_dates = new_datetimes.map(lambda x: group_data['datetime'].iloc[(group_data['datetime'] - x).abs().idxmin()])\n",
    "\n",
    "\n",
    "    # iterate through heart data & match entries by closest datetime \n",
    "    # for heart_entry in heart_data1:\n",
    "    #     print(heart_entry)\n",
    "    \n",
    "\n",
    "    # print(type(heart_data1[0]['dateTime']))\n",
    "    # for entry in heart_data1:\n",
    "        # if entry['dateTime'] in group_data['datetime']:\n",
    "        #     print('asdfasdf')\n",
    "    break \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-06-19 12:15:00', '2023-06-19 13:40:00'], dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2023-06-19 12:00:00', '2023-06-19 13:30:00'], dtype='datetime64[ns]', freq=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_original</th>\n",
       "      <th>value_original</th>\n",
       "      <th>closest_datetime</th>\n",
       "      <th>new_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-19 12:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-06-19 12:00:00</td>\n",
       "      <td>2023-06-19 12:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-19 13:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-06-19 13:30:00</td>\n",
       "      <td>2023-06-19 13:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-19 14:45:00</td>\n",
       "      <td>3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime_original  value_original    closest_datetime        new_datetime\n",
       "0 2023-06-19 12:00:00               1 2023-06-19 12:00:00 2023-06-19 12:15:00\n",
       "1 2023-06-19 13:30:00               2 2023-06-19 13:30:00 2023-06-19 13:40:00\n",
       "2 2023-06-19 14:45:00               3                 NaT                 NaT"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original DataFrame with datetime entries\n",
    "df_original = pd.DataFrame({\n",
    "    'datetime_original': pd.to_datetime(['2023-06-19 12:00:00', '2023-06-19 13:30:00', '2023-06-19 14:45:00']),\n",
    "    'value_original': [1, 2, 3]\n",
    "})\n",
    "\n",
    "# New datetime entries\n",
    "new_datetimes = pd.to_datetime(['2023-06-19 12:15:00', '2023-06-19 13:40:00'])\n",
    "print(new_datetimes)\n",
    "\n",
    "# Find closest respective dates\n",
    "closest_dates = new_datetimes.map(lambda x: df_original['datetime_original'].iloc[(df_original['datetime_original'] - x).abs().idxmin()])\n",
    "\n",
    "# Create a DataFrame with the closest respective dates\n",
    "df_new = pd.DataFrame({'closest_datetime': closest_dates, 'new_datetime': new_datetimes})\n",
    "\n",
    "# Merge the original DataFrame with the closest respective dates\n",
    "merged_df = pd.merge(df_original, df_new, left_on='datetime_original', right_on='closest_datetime', how='outer')\n",
    "\n",
    "merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_num</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Time (s)</th>\n",
       "      <th>X (m/s^2)</th>\n",
       "      <th>Y (m/s^2)</th>\n",
       "      <th>Z (m/s^2)</th>\n",
       "      <th>X (rad/s)</th>\n",
       "      <th>Y (rad/s)</th>\n",
       "      <th>Z (rad/s)</th>\n",
       "      <th>name_climber</th>\n",
       "      <th>grading</th>\n",
       "      <th>num_attempt</th>\n",
       "      <th>fall_top</th>\n",
       "      <th>outdoor</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-07 16:36:31.299000-02:00</td>\n",
       "      <td>0.202257</td>\n",
       "      <td>0.616807</td>\n",
       "      <td>0.545096</td>\n",
       "      <td>-0.119170</td>\n",
       "      <td>-0.738735</td>\n",
       "      <td>-0.693665</td>\n",
       "      <td>-0.053444</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-07 16:36:31.399774729-02:00</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.427085</td>\n",
       "      <td>-0.449999</td>\n",
       "      <td>0.075464</td>\n",
       "      <td>-0.314339</td>\n",
       "      <td>-0.378076</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-07 16:36:31.500549459-02:00</td>\n",
       "      <td>0.604846</td>\n",
       "      <td>0.570240</td>\n",
       "      <td>0.152899</td>\n",
       "      <td>-0.213106</td>\n",
       "      <td>-0.273812</td>\n",
       "      <td>-0.442562</td>\n",
       "      <td>-0.130227</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-07 16:36:31.601324189-02:00</td>\n",
       "      <td>0.806141</td>\n",
       "      <td>0.295633</td>\n",
       "      <td>-0.453686</td>\n",
       "      <td>0.244799</td>\n",
       "      <td>-0.260747</td>\n",
       "      <td>-0.114135</td>\n",
       "      <td>-0.019194</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-07 16:36:31.702098919-02:00</td>\n",
       "      <td>1.007435</td>\n",
       "      <td>0.206272</td>\n",
       "      <td>-0.927811</td>\n",
       "      <td>-0.512616</td>\n",
       "      <td>-0.160211</td>\n",
       "      <td>-0.226173</td>\n",
       "      <td>-0.211577</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5186</th>\n",
       "      <td>40</td>\n",
       "      <td>2023-06-14 17:02:20.736479365-02:00</td>\n",
       "      <td>62.783481</td>\n",
       "      <td>0.138590</td>\n",
       "      <td>-1.738872</td>\n",
       "      <td>-0.396787</td>\n",
       "      <td>-0.371624</td>\n",
       "      <td>-0.194527</td>\n",
       "      <td>-0.130351</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5187</th>\n",
       "      <td>40</td>\n",
       "      <td>2023-06-14 17:02:20.938609523-02:00</td>\n",
       "      <td>62.984758</td>\n",
       "      <td>-0.756452</td>\n",
       "      <td>-0.380505</td>\n",
       "      <td>0.312611</td>\n",
       "      <td>0.064059</td>\n",
       "      <td>0.111573</td>\n",
       "      <td>-0.053014</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>40</td>\n",
       "      <td>2023-06-14 17:02:21.140739682-02:00</td>\n",
       "      <td>63.186036</td>\n",
       "      <td>-0.321295</td>\n",
       "      <td>-0.189666</td>\n",
       "      <td>-0.070279</td>\n",
       "      <td>-0.062600</td>\n",
       "      <td>-0.059749</td>\n",
       "      <td>-0.085358</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>40</td>\n",
       "      <td>2023-06-14 17:02:21.342869841-02:00</td>\n",
       "      <td>63.387314</td>\n",
       "      <td>-0.421361</td>\n",
       "      <td>-0.344314</td>\n",
       "      <td>0.504001</td>\n",
       "      <td>0.049513</td>\n",
       "      <td>-0.251242</td>\n",
       "      <td>0.149490</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>40</td>\n",
       "      <td>2023-06-14 17:02:21.545000-02:00</td>\n",
       "      <td>63.588592</td>\n",
       "      <td>1.043850</td>\n",
       "      <td>0.042929</td>\n",
       "      <td>-0.344855</td>\n",
       "      <td>0.249277</td>\n",
       "      <td>-1.278707</td>\n",
       "      <td>0.013051</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33485 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_num                             datetime   Time (s)  X (m/s^2)  \\\n",
       "0            15     2023-06-07 16:36:31.299000-02:00   0.202257   0.616807   \n",
       "1            15  2023-06-07 16:36:31.399774729-02:00   0.403552   0.427085   \n",
       "2            15  2023-06-07 16:36:31.500549459-02:00   0.604846   0.570240   \n",
       "3            15  2023-06-07 16:36:31.601324189-02:00   0.806141   0.295633   \n",
       "4            15  2023-06-07 16:36:31.702098919-02:00   1.007435   0.206272   \n",
       "...         ...                                  ...        ...        ...   \n",
       "5186         40  2023-06-14 17:02:20.736479365-02:00  62.783481   0.138590   \n",
       "5187         40  2023-06-14 17:02:20.938609523-02:00  62.984758  -0.756452   \n",
       "5188         40  2023-06-14 17:02:21.140739682-02:00  63.186036  -0.321295   \n",
       "5189         40  2023-06-14 17:02:21.342869841-02:00  63.387314  -0.421361   \n",
       "5190         40     2023-06-14 17:02:21.545000-02:00  63.588592   1.043850   \n",
       "\n",
       "      Y (m/s^2)  Z (m/s^2)  X (rad/s)  Y (rad/s)  Z (rad/s)  name_climber  \\\n",
       "0      0.545096  -0.119170  -0.738735  -0.693665  -0.053444             0   \n",
       "1     -0.449999   0.075464  -0.314339  -0.378076   0.015612             0   \n",
       "2      0.152899  -0.213106  -0.273812  -0.442562  -0.130227             0   \n",
       "3     -0.453686   0.244799  -0.260747  -0.114135  -0.019194             0   \n",
       "4     -0.927811  -0.512616  -0.160211  -0.226173  -0.211577             0   \n",
       "...         ...        ...        ...        ...        ...           ...   \n",
       "5186  -1.738872  -0.396787  -0.371624  -0.194527  -0.130351             1   \n",
       "5187  -0.380505   0.312611   0.064059   0.111573  -0.053014             1   \n",
       "5188  -0.189666  -0.070279  -0.062600  -0.059749  -0.085358             1   \n",
       "5189  -0.344314   0.504001   0.049513  -0.251242   0.149490             1   \n",
       "5190   0.042929  -0.344855   0.249277  -1.278707   0.013051             1   \n",
       "\n",
       "      grading  num_attempt  fall_top  outdoor  Unnamed: 0  \n",
       "0         4.7            1         0      0.0         NaN  \n",
       "1         4.7            1         0      0.0         NaN  \n",
       "2         4.7            1         0      0.0         NaN  \n",
       "3         4.7            1         0      0.0         NaN  \n",
       "4         4.7            1         0      0.0         NaN  \n",
       "...       ...          ...       ...      ...         ...  \n",
       "5186      5.3            1         0      NaN         NaN  \n",
       "5187      5.3            1         0      NaN         NaN  \n",
       "5188      5.3            1         0      NaN         NaN  \n",
       "5189      5.3            1         0      NaN         NaN  \n",
       "5190      5.3            1         0      NaN         NaN  \n",
       "\n",
       "[33485 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tim = pd.read_csv('/Users/ryonamba/Documents/VU/VU-master_year_1/ML_quantified_self/ML4QS/datasets/raw_data_tim_copy.csv')\n",
    "data_sien = pd.read_csv('/Users/ryonamba/Documents/VU/VU-master_year_1/ML_quantified_self/ML4QS/datasets/raw_data_sien_copy.csv')\n",
    "data_tim2 = pd.read_csv('/Users/ryonamba/Documents/VU/VU-master_year_1/ML_quantified_self/ML4QS/datasets/raw_data_tim_2_copy.csv')\n",
    "data_sien2 = pd.read_csv('/Users/ryonamba/Documents/VU/VU-master_year_1/ML_quantified_self/ML4QS/datasets/raw_data_sien_copy.csv')\n",
    "\n",
    "\n",
    "data_tim = data_tim.drop(columns = ['Unnamed: 0'])\n",
    "data_sien = data_sien.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = cd.combine_start_dfs(data_sien, data_sien2, data_tim, data_tim2)\n",
    "df['name_climber'] = df['name_climber'].map({'sien':0,'tim':1})\n",
    "df\n",
    "df = df.drop(columns = ['Time (s).1'])\n",
    "df = cd.drop_climber_rating(df)\n",
    "df = cd.add_datetime(df)\n",
    "df = cd.cut_fall(df)\n",
    "\n",
    "\n",
    "df.grading = df.grading.apply(fe.french_grade_to_num)\n",
    "\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variables</th>\n",
       "      <th>number values</th>\n",
       "      <th>number unique values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entry_num</td>\n",
       "      <td>18134</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datetime</td>\n",
       "      <td>18134</td>\n",
       "      <td>18134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time (s)</td>\n",
       "      <td>18134</td>\n",
       "      <td>18134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X (m/s^2)</td>\n",
       "      <td>18134</td>\n",
       "      <td>18131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y (m/s^2)</td>\n",
       "      <td>18134</td>\n",
       "      <td>18086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Z (m/s^2)</td>\n",
       "      <td>18134</td>\n",
       "      <td>18111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Time (s).1</td>\n",
       "      <td>18134</td>\n",
       "      <td>18134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X (rad/s)</td>\n",
       "      <td>18134</td>\n",
       "      <td>18133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Y (rad/s)</td>\n",
       "      <td>18134</td>\n",
       "      <td>18134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Z (rad/s)</td>\n",
       "      <td>18134</td>\n",
       "      <td>18132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>name_climber</td>\n",
       "      <td>18134</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>grading</td>\n",
       "      <td>18134</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>num_attempt</td>\n",
       "      <td>18134</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fall_top</td>\n",
       "      <td>18134</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>climbers_rating</td>\n",
       "      <td>18134</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Variables  number values  number unique values\n",
       "0         entry_num          18134                    25\n",
       "1          datetime          18134                 18134\n",
       "2          Time (s)          18134                 18134\n",
       "3         X (m/s^2)          18134                 18131\n",
       "4         Y (m/s^2)          18134                 18086\n",
       "5         Z (m/s^2)          18134                 18111\n",
       "6        Time (s).1          18134                 18134\n",
       "7         X (rad/s)          18134                 18133\n",
       "8         Y (rad/s)          18134                 18134\n",
       "9         Z (rad/s)          18134                 18132\n",
       "10     name_climber          18134                     2\n",
       "11          grading          18134                     9\n",
       "12      num_attempt          18134                     3\n",
       "13         fall_top          18134                     2\n",
       "14  climbers_rating          18134                     3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code from DMT\n",
    "# datatypes - NOTE: subject to change (only accelerometer & gyrometer rn)\n",
    "types = ['id','datetime', 'numeric', 'numeric', 'numeric', 'numeric', 'numeric', 'numeric', 'categorical', 'ordinal', ] \n",
    "\n",
    "# nb of values \n",
    "n_values = [data[var].count() for var in data]\n",
    "\n",
    "# nb of unique values\n",
    "n_unique = [data[var].nunique() for var in data]\n",
    "\n",
    "\n",
    "# TODO: do once we have the final variables (eg. for grade)\n",
    "## mean + std \n",
    "# mean_std = []\n",
    "\n",
    "# for var in data: \n",
    "#     if var not in ['datetime', 'entry_num']: # TODO \n",
    "#         mean = round(data[var].mean(), 2)\n",
    "#         std = round(data[var].std(), 2) \n",
    "#         res = f'{mean} ({std})'\n",
    "#         mean_std.append(res)\n",
    "# mean_std.insert(0,'Na')\n",
    "# mean_std.insert(0,'Na')\n",
    "\n",
    "# # range of values\n",
    "# val_range = []\n",
    "# for var in data:\n",
    "#     if var != 'id':\n",
    "#         r = (data[var].min(), data[var].max())\n",
    "#         if var != 'time':\n",
    "#             r = (round(r[0]), round(r[1]))\n",
    "#         else:\n",
    "#             r = (data['time'].dt.date.min(), data['time'].dt.date.max())\n",
    "#         val_range.append(r)\n",
    "#         r = data['time'].dt.date\n",
    "# val_range.insert(0, 'Na')\n",
    "\n",
    "# # date range \n",
    "# time_range = []\n",
    "# for var in data: \n",
    "#     # if var != 'id':\n",
    "#     grouped = data.groupby(var)['time'].min()\n",
    "#     r = (grouped.dt.date.min(), grouped.dt.date.max())\n",
    "#     time_range.append(r)\n",
    "\n",
    "\n",
    "# # missing values before time aggregation TODO: do for heartrate only ig\n",
    "# missing_before_agg = data.isna().sum().tolist()\n",
    "\n",
    "# # missing values after time aggregation -> fill this in manually... \n",
    "# # automatic 14 for each except call & sms \n",
    "# # + 13 for activity \n",
    "# # + 1 for 'circumplex.arousal','circumplex.valence', 'mood' & -2 cuz there were like 2 days of measurements in the first 14 days? \n",
    "# # temp_data = fn.group_data(data, count=False)\n",
    "# # missing_after_agg = temp_data.isna().sum().tolist()\n",
    "# # missing_after_agg.insert(0, 0)\n",
    "\n",
    "\n",
    "# missing_after_agg = [0 for i in range(len(data.columns))]\n",
    "# for i, var in enumerate(data.columns):\n",
    "#     if var == 'sms' or var == 'call' or var == 'id' or var == 'time': \n",
    "#         continue\n",
    "#     if var == 'circumplex.arousal' or var == 'circumplex.valence' or var == 'mood':\n",
    "#         missing_after_agg[i] += 1\n",
    "#     missing_after_agg[i] += 14\n",
    "#     if var == 'activity':\n",
    "#         missing_after_agg[i] += 13\n",
    "\n",
    "\n",
    "\n",
    "data_table = pd.DataFrame({'Variables': data.columns, \n",
    "                    # 'Data types': types, \n",
    "                    'number values': n_values, \n",
    "                    'number unique values': n_unique, \n",
    "                    # 'Mean (std)': mean_std,\n",
    "                    # 'Value range': val_range,\n",
    "                    # 'Date range': time_range, \n",
    "                    # 'Missing values (before time aggregation)': missing_before_agg,\n",
    "                    # 'Missing values (after time aggregation)': missing_after_agg\n",
    "                    })\n",
    "data_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
